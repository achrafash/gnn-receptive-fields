{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine_tuning_on_enzymes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN+DWi1WfdKjW72CBqKZryr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchrafAsh/gnn-receptive-fields/blob/main/fine_tuning_on_enzymes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr7qeoQ_wWK_"
      },
      "source": [
        "ENZYMES is a dataset of long-range graphs (molecules) for graph classification. This is what make this experiment interesting.\n",
        "\n",
        "For recall:\n",
        "- over-smoothing happens on short-range graphs (because you can't apply too many layers)\n",
        "- over-squashing happens on long-range graphs\n",
        "\n",
        "In my opinion, over-smoothing should happen on long-range graphs where a lot of layers are required (at least 8 layers for a problem radius of 8) which will ultimately lead to over-smoothing. Whereas in short-range graphs, we have the luxury of smoothing a lot because close neighbors are similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TxfxJYcwTOB"
      },
      "source": [
        "## **ðŸš€Setting up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwkFuA4KwEvu",
        "outputId": "7ab4cff0-3033-4395-98b4-40c73830be68"
      },
      "source": [
        "import os, sys\n",
        "import os.path as osp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "try:\n",
        "    os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "except:\n",
        "    pass\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/mnt; to attempt to forcibly remount, call drive.mount(\"/content/mnt\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMm556sbwO2V"
      },
      "source": [
        "# import everything\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "import yaml\n",
        "\n",
        "from functools import partial\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from torch_geometric.utils import degree, to_dense_adj, dense_to_sparse, add_self_loops, to_networkx\n",
        "from torch_geometric.nn import GCNConv, MessagePassing, Sequential\n",
        "from torch_sparse import spmm, spspmm\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCwZgrJdwQYb"
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/data.py\n",
        "\n",
        "from data import load_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogVkLFaWwjwl"
      },
      "source": [
        "## **ðŸŽ¨Designing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW30Yy5swp61"
      },
      "source": [
        "# Parameter initialization\n",
        "def xavier(tensor):\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-2)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "def zeros(tensor):\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuuLRhtuwrSr"
      },
      "source": [
        "class OurGCNConv(MessagePassing):\n",
        "    def __init__(self, num_features:int, in_channels:int, out_channels:int, k:int):\n",
        "        super().__init__(aggr='add')  # \"Add\" aggregation\n",
        "        self.k = k\n",
        "        self.lin_neb = torch.nn.Linear(num_features, out_channels)\n",
        "        self.lin_trgt = torch.nn.Linear(in_channels, out_channels)\n",
        "        \n",
        "        self.reset_parameters()\n",
        "        \n",
        "    def reset_parameters(self):\n",
        "        xavier(self.lin_neb.weight)\n",
        "        zeros(self.lin_neb.bias)\n",
        "        \n",
        "        xavier(self.lin_trgt.weight)\n",
        "        zeros(self.lin_trgt.bias)\n",
        "\n",
        "    def forward(self, x, h, edge_index):\n",
        "        # x is the input features and has shape [N, num_features]\n",
        "        # h is the hidden state and has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E] , E being the number of edges\n",
        "\n",
        "        # step 1: linearly transform node feature matrices\n",
        "        x = self.lin_neb(x)\n",
        "        h = self.lin_trgt(h)\n",
        "\n",
        "        # step 3-5: start propagating messages\n",
        "        return self.propagate(edge_index[self.k].to(device), x=x, h=h)\n",
        "\n",
        "    def message(self, x_j, h_i, edge_index, size):\n",
        "        # x_j is the input features of the neighbors and has shape [E, out_channels] (has already been multiplied by the weight matrix)\n",
        "\n",
        "        # step 3: normalize node features\n",
        "        row, col = edge_index\n",
        "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        out = norm.view(-1, 1) * x_j\n",
        "\n",
        "        return out + h_i\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels] is the output of self.message()\n",
        "\n",
        "        # step 5: return new node embeddings\n",
        "        return aggr_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ7yVxevwtIp"
      },
      "source": [
        "# the real deal\n",
        "class OurModel(torch.nn.Module):\n",
        "    def __init__(self, num_layers:int, hidden_dim:int, num_features:int, \n",
        "                 num_classes:int, propagation_steps:int=2, dropout:float=0.5):\n",
        "        super().__init__()\n",
        "        self.propagation_steps = propagation_steps\n",
        "        \n",
        "        self.alpha = torch.nn.Parameter(torch.tensor(0.5), requires_grad=True)\n",
        "        # Embedding input features\n",
        "        self.in_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=num_features, out_features=hidden_dim),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        # Convolutional layers\n",
        "        self.conv_layers = self.create_layers(num_layers=num_layers,\n",
        "                                              hidden_dim=hidden_dim,\n",
        "                                              dropout=dropout)\n",
        "        # Readout function\n",
        "        self.readout = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=hidden_dim, out_features=num_classes),\n",
        "            torch.nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def create_layers(self, num_layers:int, hidden_dim:int, dropout:float):\n",
        "        layers = [(OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=0), \"x, x, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")]\n",
        "        \n",
        "        for k in range(1, num_layers):\n",
        "            layers += [\n",
        "                (OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=k), \"x, h, edge_index -> h\"),\n",
        "                # (GCNConv(hidden_dim, hidden_dim), \"h, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")\n",
        "            ]\n",
        "        return Sequential(\"x, edge_index\", layers)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv_layers.reset_parameters()\n",
        "\n",
        "\n",
        "    def propagate(self, x, edge_index):\n",
        "        # add self loops\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        \n",
        "        # normalize\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # dense_adj = to_dense_adj(edge_index).squeeze(0)\n",
        "        # edge_index_pow = torch.eye(G.num_nodes).to(device)\n",
        "        # prop_repr = edge_index_pow.clone()\n",
        "        # for _ in range(self.propagation_steps):\n",
        "        #     edge_index_pow = torch.mm(dense_adj, edge_index_pow)\n",
        "        #     prop_repr += edge_index_pow\n",
        "        # return torch.mm(prop_repr, x)\n",
        "        \n",
        "        # APPNP propagation scheme\n",
        "        z = x.clone()\n",
        "        for _ in range(self.propagation_steps):\n",
        "            z = spmm(edge_index, norm, x.size(0), x.size(0), z) * (1-self.alpha) + x * self.alpha\n",
        "        return z\n",
        "\n",
        "        # another propagation scheme (sum of the powers of A)\n",
        "        # props = []\n",
        "        # for _ in range(self.propagation_steps):\n",
        "        #     x= spmm(edge_index, norm, x.size(0), x.size(0), x)\n",
        "        #     props.append(x)\n",
        "        # return sum(props)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        embeddings = self.in_mlp(x)\n",
        "        h = self.conv_layers(embeddings, edge_index)\n",
        "        out = self.propagate(h, edge_index[0].to(device))\n",
        "        return h, self.readout(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xszn3hhwv8I"
      },
      "source": [
        "## **ðŸ§°Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKCOx2w8w074"
      },
      "source": [
        "def get_k_neighbors(k: int, edge_index: torch.Tensor):\n",
        "    \"\"\"Returns the l-hop neighbors for l between 1 (the adjacency matrix) and k (given depth)\n",
        "\n",
        "    Args:\n",
        "        - k (int): size of the maximum neighborhood\n",
        "    \"\"\"\n",
        "    \n",
        "    output = [edge_index]\n",
        "    dense_adj = to_dense_adj(edge_index).squeeze(0)\n",
        "    dense_nebs = [dense_adj.clone()]\n",
        "    adj_pow = dense_adj.clone()\n",
        "\n",
        "    for l in tqdm(range(1, k)):\n",
        "        adj_pow = torch.mm(dense_adj, adj_pow)\n",
        "        k_neb = torch.where(\n",
        "            torch.where(adj_pow > 0, 1, 0) - sum(dense_nebs) > 0,\n",
        "            1,\n",
        "            0\n",
        "        )\n",
        "        dense_nebs.append(k_neb)\n",
        "        output.append(dense_to_sparse(k_neb)[0])\n",
        "    \n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F420NyXHw35S"
      },
      "source": [
        "# count model parameters\n",
        "def count_parameters(model: torch.nn.Module):\n",
        "    total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"The model has {total_parameters:,} parameters\")\n",
        "\n",
        "    return total_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9alC_myw5zm"
      },
      "source": [
        "def make(config):\n",
        "    # Make the model\n",
        "    model = OurModel(num_layers=config['num_layers'],\n",
        "                     hidden_dim=config['hidden_dim'],\n",
        "                     num_features=cora_dataset.num_features,\n",
        "                     num_classes=cora_dataset.num_classes,\n",
        "                     propagation_steps=config['propagation_steps'],\n",
        "                     dropout=config['dropout']).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=config['learning_rate'],\n",
        "                                 weight_decay=config['weight_decay'])\n",
        "    \n",
        "    return model, criterion, optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "662RlCxaw7c_"
      },
      "source": [
        "def train(model, all_edge_index, criterion, optimizer, config):\n",
        "    outputs = []\n",
        "    \n",
        "    for _ in range(config['runs']):\n",
        "        for epoch in tqdm(range(config['epochs'])):\n",
        "            total_loss = 0\n",
        "            for graph in data:\n",
        "                loss = train_step(model, all_edge_index, graph.x, optimizer, criterion)\n",
        "                total_loss += loss\n",
        "            \n",
        "            # test the model\n",
        "            outs = test(model, all_edge_index, data, criterion)\n",
        "            outs['epoch'] = epoch\n",
        "            outs['id'] = config['id']\n",
        "            outs['hidden_dim'] = config['hidden_dim']\n",
        "            outs['weight_decay'] = config['weight_decay']\n",
        "            outs['num_layers'] = config['num_layers']\n",
        "            outs['learning_rate'] = config['learning_rate']\n",
        "            outs['dropout'] = config['dropout']\n",
        "            outs['propagation_steps'] = config['propagation_steps']\n",
        "\n",
        "            outputs.append(outs)\n",
        "\n",
        "    return pd.DataFrame(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8MRXY7Rw9NM"
      },
      "source": [
        "def train_step(model, all_edge_index, x, optimizer, criterion):\n",
        "    \"\"\"Performs one training step\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    # Forward pass\n",
        "    _, out = model(x.to(device), all_edge_index)\n",
        "    loss = criterion(out[G.train_mask], G.y[G.train_mask])\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c2Zd9jHw-_F"
      },
      "source": [
        "def test(model, all_edge_index, criterion, metrics=[]):\n",
        "    \"\"\"\n",
        "    Metrics is a list of tuple ('metric_name', metric_func) where the metric \n",
        "    function takes the last representation matrix and returns a scalar.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        h, logits = model(G.x, all_edge_index)\n",
        "\n",
        "    outs = {}\n",
        "    h = h.detach().cpu()\n",
        "    for (name, metric) in metrics:\n",
        "        outs[name] = metric(h)\n",
        "\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = G[f'{key}_mask']\n",
        "        loss = criterion(logits[mask], G.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(G.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs[f'{key}_loss'] = loss\n",
        "        outs[f'{key}_acc'] = acc\n",
        "    \n",
        "    return outs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhqI6ux3xAsq"
      },
      "source": [
        "def model_pipeline(config):\n",
        "    # create the model\n",
        "    model, criterion, optimizer = make(config)\n",
        "    config['total_parameters'] = count_parameters(model)\n",
        "    \n",
        "    # compute different depth edge_index\n",
        "    all_edge_index = get_k_neighbors(config['num_layers'])\n",
        "\n",
        "    # train the model for different parameters\n",
        "    logs = train(model, all_edge_index, criterion, optimizer, config)\n",
        "\n",
        "    # repr = tsne_plot(model, all_edge_index, title=\"Last hidden representations\")\n",
        "\n",
        "    return model, logs, config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJOuyp2fxDUZ"
      },
      "source": [
        "## **ðŸ•¸ ENZYMES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIS0sGoOxGqh"
      },
      "source": [
        "%%capture\n",
        "path = osp.join(os.getcwd(), 'data')\n",
        "enzymes = load_dataset(path, 'ENZYMES')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tciCvLY2xVh9"
      },
      "source": [
        "## **ðŸ”Fine tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inXNjXDLpurv"
      },
      "source": [
        "grid = dict(\n",
        "    num_layers=[1],\n",
        "    hidden_dim=[16,24],\n",
        "    propagation_steps=[6,7,8,9],\n",
        "    learning_rate=np.logspace(-3, -2, 5),\n",
        "    weight_decay=np.logspace(-3, -1, 5),\n",
        "    dropout=np.linspace(0.4,0.5, 4),\n",
        "    epochs=200,\n",
        "    runs=2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFzylpQxpurx"
      },
      "source": [
        "id = 0\n",
        "all_logs=None\n",
        "\n",
        "for num_layers in grid['num_layers']:\n",
        "    for hidden_dim in grid['hidden_dim']:\n",
        "        for propagation_steps in grid['propagation_steps']:\n",
        "            for learning_rate in grid['learning_rate']:\n",
        "                for weight_decay in grid['weight_decay']:\n",
        "                    for dropout in grid['dropout']:\n",
        "                        model, logs, hyperparameters = model_pipeline({\n",
        "                            'id':id,\n",
        "                            'num_layers':num_layers,\n",
        "                            'hidden_dim':hidden_dim,\n",
        "                            'propagation_steps':propagation_steps,\n",
        "                            'learning_rate':learning_rate,\n",
        "                            'weight_decay':weight_decay,\n",
        "                            'dropout':dropout,\n",
        "                            'epochs':200,\n",
        "                            'runs':2\n",
        "                        })\n",
        "\n",
        "                        print(logs.query(f'id == {id} & epoch == 199'))\n",
        "\n",
        "                        if id == 0:\n",
        "                            all_logs = logs\n",
        "                        else:\n",
        "                            all_logs = pd.concat([all_logs, logs], ignore_index=True)\n",
        "                        \n",
        "                        id += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9RvCQQt-YB"
      },
      "source": [
        "all_logs.query('epoch == 199 & train_acc == 1.0 & test_acc > 0.8 & val_acc > 0.76').sort_values(by=[\"test_acc\", \"val_acc\"], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}