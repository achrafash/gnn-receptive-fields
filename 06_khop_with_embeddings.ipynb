{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_khop_with_embeddings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxE4NTe2L4FM1uCdC9bYqY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "968672cf65e74311abe4d775de0b19bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4dd79ad5f8534129a396c26058fbfd19",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53415477f399498e95517c72f52abd25",
              "IPY_MODEL_b909b225d0134662b9636f0b64805638",
              "IPY_MODEL_f12569d7626e4ebf95feba901b8c2c7a"
            ]
          }
        },
        "4dd79ad5f8534129a396c26058fbfd19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53415477f399498e95517c72f52abd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43a4edab5d464701abe505c6bd1b739f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8591faa3e7e044839fa36a9319c4da72"
          }
        },
        "b909b225d0134662b9636f0b64805638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c83c510101847ecaee4ccf402881ab1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f8f6c53c694410b8e0c5497a08d8320"
          }
        },
        "f12569d7626e4ebf95feba901b8c2c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95249bda418b484b833db38801f2a017",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/0 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8884f96cceef4362888ab69a5d73014e"
          }
        },
        "43a4edab5d464701abe505c6bd1b739f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8591faa3e7e044839fa36a9319c4da72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c83c510101847ecaee4ccf402881ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f8f6c53c694410b8e0c5497a08d8320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95249bda418b484b833db38801f2a017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8884f96cceef4362888ab69a5d73014e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba50998eb5354212a3a9e5a8bfa33f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_308a434e45094e88b022d203b9c38d69",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a9105642a924179b4bcd253da310965",
              "IPY_MODEL_f31b361e617e4eb5900350f23cbc36a4",
              "IPY_MODEL_ac480f41769c41e5ac23b81c4c292115"
            ]
          }
        },
        "308a434e45094e88b022d203b9c38d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a9105642a924179b4bcd253da310965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_795cf9ac0faa4b61b2bba7b326150d41",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd1918ee42e54d08887727e58fa119c2"
          }
        },
        "f31b361e617e4eb5900350f23cbc36a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31c3237f0d1e47d9a8a63fef804a4cc1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3306180348a44d38e6a45451740d4f6"
          }
        },
        "ac480f41769c41e5ac23b81c4c292115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8581faa755314fe486c02a9b7a94f97d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [00:02&lt;00:00,  3.65it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0c448a6187e4049a8ee9c3e5649775c"
          }
        },
        "795cf9ac0faa4b61b2bba7b326150d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd1918ee42e54d08887727e58fa119c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31c3237f0d1e47d9a8a63fef804a4cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3306180348a44d38e6a45451740d4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8581faa755314fe486c02a9b7a94f97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0c448a6187e4049a8ee9c3e5649775c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AchrafAsh/gnn-receptive-fields/blob/main/06_khop_with_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sclJ_0n4BFKs"
      },
      "source": [
        "After some reflection (and seeing that our model had way too many parameters), we realised something weird happening in the design of Graph Neural Networks.\n",
        "Most GNNs, if not all, are embedding the input features in the first layer which has a receptive field containing only the direct neighbors.\n",
        "It leads to a very biased embedding (100% attention from the direct neighbors) which could potentially cause a loss of information that is irrelevant for the direct neighbors, but highly relevant for remote ones or even for the task at hand.\n",
        "\n",
        "Because our approach required to compute new embeddings for each k-hop neighborhood, we realised that this was not an ideal way of computing embeddings.\n",
        "\n",
        "In this notebook, we try to design a new Message Passing GNN with an initial MLP that serves as an embedding layer from which we then operate our different convolutional layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKZmfT7qLs-2"
      },
      "source": [
        "## **ðŸš€ Setting up the environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orLdyl_jAdh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909bd30f-0da6-4dd4-b352-19a3fd717609"
      },
      "source": [
        "import os, sys\n",
        "import os.path as osp\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "try:\n",
        "    os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "except:\n",
        "    pass\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/mnt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaLdo83XCNT6"
      },
      "source": [
        "# import everything\n",
        "import math\n",
        "import random\n",
        "import copy\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "import yaml\n",
        "\n",
        "from functools import partial\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from torch_geometric.utils import degree, to_dense_adj, dense_to_sparse, add_self_loops, to_networkx\n",
        "from torch_geometric.nn import GCNConv, MessagePassing, Sequential\n",
        "from torch_sparse import spmm\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKOmo-G0o6eG"
      },
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/data.py\n",
        "!wget https://raw.githubusercontent.com/AchrafAsh/gnn-receptive-fields/main/utils.py\n",
        "\n",
        "from data import load_dataset\n",
        "from utils import save_experiment"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZFgW_W4Looj"
      },
      "source": [
        "## **ðŸŽ¨ Designing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoOwBE0ICew_"
      },
      "source": [
        "# Parameter initialization\n",
        "def xavier(tensor):\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-2)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "def zeros(tensor):\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfHDhO-ULqOT"
      },
      "source": [
        "#### **Our version of the GCNConv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jQEIzoIIsk8"
      },
      "source": [
        "class OurGCNConv(MessagePassing):\n",
        "    def __init__(self, num_features:int, in_channels:int, out_channels:int, k:int):\n",
        "        super().__init__(aggr='add')  # \"Add\" aggregation\n",
        "        self.k = k\n",
        "        self.lin_neb = torch.nn.Linear(num_features, out_channels)\n",
        "        self.lin_trgt = torch.nn.Linear(in_channels, out_channels)\n",
        "        \n",
        "        self.reset_parameters()\n",
        "        \n",
        "    def reset_parameters(self):\n",
        "        xavier(self.lin_neb.weight)\n",
        "        zeros(self.lin_neb.bias)\n",
        "        \n",
        "        xavier(self.lin_trgt.weight)\n",
        "        zeros(self.lin_trgt.bias)\n",
        "\n",
        "    def forward(self, x, h, edge_index):\n",
        "        # x is the input features and has shape [N, num_features]\n",
        "        # h is the hidden state and has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E] , E being the number of edges\n",
        "\n",
        "        # step 1: linearly transform node feature matrices\n",
        "        x = self.lin_neb(x)\n",
        "        h = self.lin_trgt(h)\n",
        "\n",
        "        # step 3-5: start propagating messages\n",
        "        return self.propagate(edge_index[self.k].to(device), x=x, h=h)\n",
        "\n",
        "    def message(self, x_j, h_i, edge_index, size):\n",
        "        # x_j is the input features of the neighbors and has shape [E, out_channels] (has already been multiplied by the weight matrix)\n",
        "\n",
        "        # step 3: normalize node features\n",
        "        row, col = edge_index\n",
        "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        out = norm.view(-1, 1) * x_j\n",
        "\n",
        "        return out + h_i\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels] is the output of self.message()\n",
        "\n",
        "        # step 5: return new node embeddings\n",
        "        return aggr_out"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXHyp3eWLtnC"
      },
      "source": [
        "#### **Our full model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ6WNylDIuw9"
      },
      "source": [
        "# the real deal\n",
        "class OurModel(torch.nn.Module):\n",
        "    def __init__(self, num_layers:int, hidden_dim:int, num_features:int, \n",
        "                 num_classes:int, propagation_steps:int=2, dropout:float=0.5):\n",
        "        super().__init__()\n",
        "        self.propagation_steps = propagation_steps\n",
        "        \n",
        "        self.alpha = torch.nn.Parameter(torch.tensor(0.5), requires_grad=True)\n",
        "        # Embedding input features\n",
        "        self.in_mlp = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=num_features, out_features=hidden_dim),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        # Convolutional layers\n",
        "        self.conv_layers = self.create_layers(num_layers=num_layers,\n",
        "                                              hidden_dim=hidden_dim,\n",
        "                                              dropout=dropout)\n",
        "        # Readout function\n",
        "        self.readout = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=hidden_dim, out_features=num_classes),\n",
        "            torch.nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def create_layers(self, num_layers:int, hidden_dim:int, dropout:float):\n",
        "        layers = [(OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=0), \"x, x, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")]\n",
        "        \n",
        "        for k in range(1, num_layers):\n",
        "            layers += [\n",
        "                (OurGCNConv(num_features=hidden_dim, in_channels=hidden_dim, out_channels=hidden_dim, k=k), \"x, h, edge_index -> h\"),\n",
        "                # (GCNConv(hidden_dim, hidden_dim), \"h, edge_index -> h\"),\n",
        "                (torch.nn.ReLU(inplace=True)),\n",
        "                (torch.nn.Dropout(p=dropout), \"h -> h\")\n",
        "            ]\n",
        "        return Sequential(\"x, edge_index\", layers)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv_layers.reset_parameters()\n",
        "\n",
        "\n",
        "    def propagate(self, x, edge_index):\n",
        "        # add self loops\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        \n",
        "        # normalize\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # GCN propagation scheme\n",
        "        # for _ in range(self.propagation_steps):\n",
        "        #     x = spmm(edge_index, norm, x.size(0), x.size(0), x)\n",
        "        \n",
        "        # return x\n",
        "        \n",
        "        # APPNP propagation scheme\n",
        "        z = x.clone()\n",
        "        for _ in range(self.propagation_steps):\n",
        "            z = spmm(edge_index, norm, x.size(0), x.size(0), z) * (1-self.alpha) + x * self.alpha\n",
        "        return z\n",
        "\n",
        "        # another propagation scheme (sum of the powers of A)\n",
        "        # props = []\n",
        "        # for _ in range(self.propagation_steps):\n",
        "        #     x= spmm(edge_index, norm, x.size(0), x.size(0), x)\n",
        "        #     props.append(x)\n",
        "        # return sum(props)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        embeddings = self.in_mlp(x)\n",
        "        h = self.conv_layers(embeddings, edge_index)\n",
        "        out = self.propagate(h, edge_index[0].to(device))\n",
        "        return h, self.readout(out)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNftl2EJKtaS"
      },
      "source": [
        "## **ðŸ§° Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBMGdT6_Cdpg"
      },
      "source": [
        "def get_k_neighbors(k: int):\n",
        "    \"\"\"Returns the l-hop neighbors for l between 1 (the adjacency matrix) and k (given depth)\n",
        "\n",
        "    Args:\n",
        "        - k (int): size of the maximum neighborhood\n",
        "    \"\"\"\n",
        "    \n",
        "    output = [G.edge_index]\n",
        "    dense_adj = to_dense_adj(G.edge_index).squeeze(0)\n",
        "    dense_nebs = [dense_adj.clone()]\n",
        "    adj_pow = dense_adj.clone()\n",
        "\n",
        "    for l in tqdm(range(1, k)):\n",
        "        adj_pow = torch.mm(dense_adj, adj_pow)\n",
        "        k_neb = torch.where(\n",
        "            torch.where(adj_pow > 0, 1, 0) - sum(dense_nebs) > 0,\n",
        "            1,\n",
        "            0\n",
        "        )\n",
        "        dense_nebs.append(k_neb)\n",
        "        output.append(dense_to_sparse(k_neb)[0])\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l23anrpnd4Id"
      },
      "source": [
        "def tsne_plot(model: torch.nn.Module, all_edge_index:list, title:str):\n",
        "    # Representing the representations with t-SNE algorithm\n",
        "    h, logits = model(G.x, all_edge_index)\n",
        "    representations = TSNE().fit_transform(h.cpu().detach().numpy())\n",
        "    \n",
        "    # Plot the 2-D representations, both with true labels and predictions\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(24, 8))\n",
        "    fig.suptitle(title, fontsize=20)\n",
        "\n",
        "    sns.scatterplot(x=representations[:,0], y=representations[:,1], hue=logits.cpu().detach().argmax(dim=1), legend='full', palette=palette, ax=ax[0]).set(title=\"Predictions\")\n",
        "    sns.scatterplot(x=representations[:,0], y=representations[:,1], hue=G.y.cpu().detach().numpy(), legend='full', palette=palette, ax=ax[1]).set(title=\"True labels\")\n",
        "    \n",
        "    fig.show()\n",
        "    return representations"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbRr8MlyKunT"
      },
      "source": [
        "# count model parameters\n",
        "def count_parameters(model: torch.nn.Module):\n",
        "    total_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"The model has {total_parameters:,} parameters\")\n",
        "\n",
        "    return total_parameters"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDFbtutLKIA"
      },
      "source": [
        "def make(config):\n",
        "    # Make the model\n",
        "    model = OurModel(num_layers=config['num_layers'],\n",
        "                     hidden_dim=config['hidden_dim'],\n",
        "                     num_features=cora_dataset.num_features,\n",
        "                     num_classes=cora_dataset.num_classes,\n",
        "                     propagation_steps=config['propagation_steps'],\n",
        "                     dropout=config['dropout']).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                 lr=config['learning_rate'],\n",
        "                                 weight_decay=config['weight_decay'])\n",
        "    \n",
        "    return model, criterion, optimizer"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BjffiwYK3d9"
      },
      "source": [
        "def train(model, all_edge_index, criterion, optimizer, config):\n",
        "    dense_adj = to_dense_adj(G.edge_index).squeeze(0)\n",
        "\n",
        "    outputs = []\n",
        "    \n",
        "    for _ in range(config['runs']):\n",
        "        for epoch in tqdm(range(config['epochs'])):\n",
        "            loss = train_step(model, all_edge_index, optimizer, criterion)\n",
        "            \n",
        "            # test the model\n",
        "            outs = test(model, all_edge_index, criterion, \n",
        "                        metrics=[('mad', mad_value),\n",
        "                                ('mad_gap', partial(mad_gap_value,dense_adj)),\n",
        "                                ('mad_sp', shortest_path_mad)])\n",
        "            outs['epoch'] = epoch\n",
        "            outputs.append(outs)\n",
        "\n",
        "    return pd.DataFrame(outputs)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65SIC5u1p9k5"
      },
      "source": [
        "def train_step(model, all_edge_index, optimizer, criterion):\n",
        "    \"\"\"Performs one training step\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    # Forward pass\n",
        "    _, out = model(G.x.to(device), all_edge_index)\n",
        "    loss = criterion(out[G.train_mask], G.y[G.train_mask])\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NoRsdlxLQ31"
      },
      "source": [
        "def test(model, all_edge_index, criterion, metrics=[]):\n",
        "    \"\"\"\n",
        "    Metrics is a list of tuple ('metric_name', metric_func) where the metric \n",
        "    function takes the last representation matrix and returns a scalar.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        h, logits = model(G.x, all_edge_index)\n",
        "\n",
        "    outs = {}\n",
        "    h = h.detach().cpu()\n",
        "    for (name, metric) in metrics:\n",
        "        outs[name] = metric(h)\n",
        "\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = G[f'{key}_mask']\n",
        "        loss = criterion(logits[mask], G.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(G.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs[f'{key}_loss'] = loss\n",
        "        outs[f'{key}_acc'] = acc\n",
        "    \n",
        "    return outs"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PRqeb7NLFPB"
      },
      "source": [
        "def model_pipeline(config):\n",
        "    # create the model\n",
        "    model, criterion, optimizer = make(config)\n",
        "    config['total_parameters'] = count_parameters(model)\n",
        "    \n",
        "    # compute different depth edge_index\n",
        "    all_edge_index = get_k_neighbors(config['num_layers'])\n",
        "\n",
        "    # train the model\n",
        "    logs = train(model, all_edge_index, criterion, optimizer, config)\n",
        "\n",
        "    # repr = tsne_plot(model, all_edge_index, title=\"Last hidden representations\")\n",
        "\n",
        "    return model, logs, config"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGv90OtKKBF4"
      },
      "source": [
        "#### Import Cora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3rGm6txKDKE",
        "outputId": "99dcd513-0f27-4111-b9ee-d1816b25b67d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%capture\n",
        "path = osp.join(os.getcwd(), 'data')\n",
        "cora_dataset = load_dataset(path, 'Cora')\n",
        "G = cora_dataset[0].to(device) # only graph of the dataset\n",
        "palette = sns.color_palette(\"hls\", cora_dataset.num_classes)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUUzwlcUOsGm"
      },
      "source": [
        "#### Over-smoothing metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-Veu6qkPaBz"
      },
      "source": [
        "def mad_value(in_arr, mask_arr=None, distance_metric='cosine', digt_num=4, target_idx=None):\n",
        "    \"\"\"The numpy version for mad (able to compute quickly)\n",
        "\n",
        "    Args:\n",
        "        - in_arr [num_nodes, hidden_dim]: the node feature matrix\n",
        "        - mask_arr [num_nodes, num_nodes]: the mask matrix of the target relations (is it the adjacency matrix?)\n",
        "        - target_idx [1, 2, 3, ...n]: the nodes indices for which we calculate the mad value\n",
        "    \"\"\"\n",
        "\n",
        "    if mask_arr == None:\n",
        "        mask_arr = torch.ones(in_arr.size(0), in_arr.size(0))\n",
        "\n",
        "    dist_arr = pairwise_distances(in_arr, in_arr, metric=distance_metric)\n",
        "    mask_dist = np.multiply(dist_arr, mask_arr.detach().cpu())\n",
        "    divide_arr = (mask_dist != 0).sum(1) + 1e-8\n",
        "    \n",
        "    node_dist = mask_dist.sum(1) / divide_arr\n",
        "    if target_idx==None:\n",
        "        mad = node_dist.mean()\n",
        "    else:\n",
        "        node_dist = np.multiply(node_dist,target_idx)\n",
        "        mad = node_dist.sum()/((node_dist!=0).sum()+1e-8)\n",
        "\n",
        "    try:\n",
        "        mad = round(mad, digt_num)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return mad"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpeJIt8VPgDi"
      },
      "source": [
        "def mad_gap_value(adj, in_arr):\n",
        "    \"\"\"Simple version of the MADGap metric implementation\n",
        "\n",
        "    Args:\n",
        "        - in_arr [node_num, hidden_dim]: the node feature matrix\n",
        "        - adj [node_num, node_num]: dense adjacency matrix\n",
        "    \"\"\"\n",
        "\n",
        "    mad_neb = mad_value(in_arr=in_arr, mask_arr=adj)\n",
        "    mad_rmt = mad_value(in_arr=in_arr, mask_arr=1-adj)\n",
        "\n",
        "    return (mad_rmt - mad_neb).item()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbFq656zPsRF"
      },
      "source": [
        "def get_shortest_path_lengths():\n",
        "    g = to_networkx(G)\n",
        "    shortest_paths = nx.shortest_path_length(g)\n",
        "\n",
        "    sp_matrix = torch.zeros((G.num_nodes, G.num_nodes), dtype=int)\n",
        "\n",
        "    for node_idx, path_lengths in shortest_paths:\n",
        "        for (idx, len) in path_lengths.items():\n",
        "            sp_matrix[node_idx, idx] = len\n",
        "    \n",
        "    return sp_matrix"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgvayx62P2wJ"
      },
      "source": [
        "shortest_path_lens = get_shortest_path_lengths()\n",
        "shortest_path_mask = torch.where(shortest_path_lens == 0, torch.tensor(0, dtype=torch.float32), 1/shortest_path_lens)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ljcmLuPu3Z"
      },
      "source": [
        "def shortest_path_mad(in_arr):\n",
        "    \"\"\"Computes MAD of all node with shortest path normalization\n",
        "\n",
        "    Args:\n",
        "        - h [num_nodes, num_nodes]: representation matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    return mad_value(in_arr=in_arr,\n",
        "                     mask_arr=shortest_path_mask)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbw0zc9ZLUge"
      },
      "source": [
        "## **ðŸ§ª Run experiments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWRrea65MFnw"
      },
      "source": [
        "#### Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJnS7eE8LS7q"
      },
      "source": [
        "config = dict(\n",
        "    num_layers=1,\n",
        "    hidden_dim=16,\n",
        "    propagation_steps=20,\n",
        "    learning_rate=0.001,\n",
        "    weight_decay=1e-5,\n",
        "    dropout=0.5,\n",
        "    epochs=10,\n",
        "    runs=1)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jKb3rh4LYNU",
        "outputId": "e5c7057a-65db-44ab-a62c-315a3b0151cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "968672cf65e74311abe4d775de0b19bd",
            "4dd79ad5f8534129a396c26058fbfd19",
            "53415477f399498e95517c72f52abd25",
            "b909b225d0134662b9636f0b64805638",
            "f12569d7626e4ebf95feba901b8c2c7a",
            "43a4edab5d464701abe505c6bd1b739f",
            "8591faa3e7e044839fa36a9319c4da72",
            "2c83c510101847ecaee4ccf402881ab1",
            "4f8f6c53c694410b8e0c5497a08d8320",
            "95249bda418b484b833db38801f2a017",
            "8884f96cceef4362888ab69a5d73014e",
            "ba50998eb5354212a3a9e5a8bfa33f49",
            "308a434e45094e88b022d203b9c38d69",
            "4a9105642a924179b4bcd253da310965",
            "f31b361e617e4eb5900350f23cbc36a4",
            "ac480f41769c41e5ac23b81c4c292115",
            "795cf9ac0faa4b61b2bba7b326150d41",
            "cd1918ee42e54d08887727e58fa119c2",
            "31c3237f0d1e47d9a8a63fef804a4cc1",
            "e3306180348a44d38e6a45451740d4f6",
            "8581faa755314fe486c02a9b7a94f97d",
            "a0c448a6187e4049a8ee9c3e5649775c"
          ]
        }
      },
      "source": [
        "model, logs, config = model_pipeline(config)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 23,608 parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "968672cf65e74311abe4d775de0b19bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba50998eb5354212a3a9e5a8bfa33f49",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIdji_8Y16jT"
      },
      "source": [
        "save_experiment('/content/test/', model, logs, config, \"what's so special about it\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}